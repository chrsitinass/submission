\section{Introduction}
%Automatically extracting events from natural text is an outstanding challenging task in information extraction.
Event extraction from text is an key underpinning technique for many natural language processing tasks.
Among diverse types of event extraction systems, the extraction task proposed by Automatic Content Extraction (ACE)
\cite{doddington2004automatic} is the most popular framework, which defines two main terminologies: \textbf{trigger}
and \textbf{argument}. The former is the word that most clearly expresses the occurrence of an event. The latter is a
phrase that serves as a participant or attribute with a specific role in an event.

Constructing training data for the ACE task currently requires heavy human involvement. To do so, linguists will first
summarize a large amount of text to generate a set of design templates about potential arguments for each event type;
then human annotators will be employed to manually label the text using the templates. The problem here is that human
annotators often generate inconsistent triggers or arguments. Consider the the question, can a prepositional phrase or
a portion of a word trigger an event, e.g., \textit{in prison} triggers an \emph{arrest} event, or, \textit{ex} in
\textit{ex-husband} triggers a \emph{divorce} event? Different annotators could give different answers event for the
same sentence. What we would like to have is an automatic way to generate consistent training data, because manual labeling is
expensive and
the contradictory data can severely affect the performance of the ACE task.

In addition to the challenge of training data generation, current ACE event extraction systems
also have two major drawbacks -- they can only support single-token trigger labeling and have
a one to one mapping from a type to an event. These restrictions make these ACE event extraction
systems in applicable when. \todo{give an example.}

%Constructing high-quality training data for the ACE task is expensive, requiring heavy human involvement. This
%typically consists of two steps. First, linguists are required to summarize a large amount of text to elaborately design
%templates about potential arguments for each event type. Second, rules should be explicitly stated to guide annotators.
%Even with detailed guidelines, there is often disagreement among human annotators about what should (not) be regarded
%as triggers/arguments. For example, can a prepositional phrase or a portion of a word trigger an event, e.g.,
%\textit{in prison} triggers an \emph{arrest} event, or, \textit{ex} in \textit{ex-husband} triggers a \emph{divorce}
%event? Furthermore, current ACE event extraction systems have two major limitations, i.e., they can only have
%single-token trigger labeling and a one to one mapping from a type to an event.
%These limitations restrict the wide adoption of ACE event extraction systems at scale.


%The aforementioned drawbacks of ACE event extraction systems motivate us to
This paper addresses the two problems mentioned above. More specifically, we try answer the following two questions:
(1) can we automatically build a dataset for event extraction without experts involved?
and (2) can we have an event extractor that handles more realistic scenarios, e.g.,  when trigger annotations are unavailable, or events with more than one type.


%It would be interesting to see (1) can we automatically build a dataset for event extraction without experts involved?
%and (2) can we have an event extractor that handles more realistic scenarios, e.g.,  when trigger annotations are unavailable, or events with more than one type.

To tackle the problem of training data generation, we use distant supervision learning to extract knowledge from structured knowledge bases (KBs) 
to automatically generate training examples. 
Recent studies \cite{mintz2009distant,zeng2015distant} ave demonstrated the
effectiveness of applying distant supervision to KBs for binary relation extraction. While promising, 
there are two major hurdles for leveraging KB to event extraction. Firstly, event structures are more complex than 
binary relations. They can be
represented as $\langle event\_type, argument_1, \ldots, argument_n\rangle$, which are n-ary relations with various
numbers of arguments. Secondly, there is no explicit trigger information in any existing knowledge base for distant 
supervision to learn over. Our key insight to the problems is that for a particular event type, there is a group of
\textbf{key arguments} which together can imply an event instead of explicit triggers. \todo{what about the structure problem?}
In this work, we utilize Freebase as our
knowledge base and Wikipedia articles as text for data generation. We show that our solutions can yield \todo{high quality training data for event extraction?} . 


%This is based on our observation that KBs often organize complex structured information in tables, which
%share similar structures with ACE event definitions. An entry of such tables usually implies the occurrence
%of certain events. On the other hand, recent studies \cite{mintz2009distant,zeng2015distant} have demonstrated the
%effectiveness of KB as distant supervision for binary relation extraction. However, there are two major challenges when
%leveraging KB to event extraction: first, event structures are more complex than binary relations. They can be
%represented as $\langle event\_type, argument_1, \ldots, argument_n\rangle$, which are n-ary relations with various
%numbers of arguments. Second, there is no explicit trigger information in any existing knowledge base. Therefore, to
%explore the distant supervision (\texttt{DS}) assumption in event extraction, we investigate different hypotheses for
%better data quality and quantity. Among them, the vital one is that, for a particular event type, there is a group of
%\textbf{key arguments} which together can imply an event instead of explicit triggers. We utilize Freebase as our
%knowledge base and Wikipedia articles as text for data generation. According to Mintz et al.
%\shortcite{mintz2009distant}, because a major source of Freebase is the tabular data from Wikipedia, making it a
%natural fit with Freebase. Figure~\ref{fig:3} illustrates examples of sentences annotated by our algorithm.

To overcome the restrictions of the current ACE systems, we propose a novel event extraction paradigm with key
arguments to characterize an event type. We consider event extraction as two sequence labeling subtasks, namely event
detection and argument detection. Inspired by neural network models in sequence labeling tasks
\cite{huang2015bidirectional,lample2016neural}, we utilize LSTM-CRF models to label key arguments and non-key arguments
in the each sentence separately. However, event structures are not simple sequences and there are strong dependencies
among key arguments. We therefore reformulate the hypotheses as constraints, and apply linear integer programming to
output multiple optimal label sequences to capture multi-type events. We show that our solution leads to better performance,
representing a significant departure from the prior works for the ACE task seen to date~\cite{ahn2006stages,li2013joint,chen2015event,nguyen2016joint}.

%Second, unlike previous studies that focus on tasks defined by ACE evaluation framework
%\cite{ahn2006stages,li2013joint,chen2015event,nguyen2016joint}, we propose a novel event extraction paradigm with key
%arguments to characterize an event type. We consider event extraction as two sequence labeling subtasks, namely event
%detection and argument detection. Inspired by neural network models in sequence labeling tasks
%\cite{huang2015bidirectional,lample2016neural}, we utilize LSTM-CRF models to label key arguments and non-key arguments
%in the each sentence separately. However, event structures are not simple sequences and there are strong dependencies
%among key arguments. We therefore reformulate the hypotheses as constraints, and apply linear integer programming to
%output multiple optimal label sequences to capture multi-type events.

%In this paper, we exploit existing structured knowledge bases, e.g., Freebase, as distant supervision to automatically
%annotate event structures from plain text without human annotations. We further propose a novel event extraction
%paradigm that harnesses key arguments to imply certain event types without explicit trigger annotations. We present an
%LSTM-CRF model with post inference to extract both Freebase-style events as well as multi-type event mentions on the
%generated dataset, which is demonstrated effective by both manual and automatic evaluations.

We apply our approach to \todo[xx}. Evaluation results show that \todo{xx}. The key contributions of this work are 
(1) a  novel event extraction paradigm that harnesses key arguments to imply certain event types without explicit trigger annotations,
and (2)  an LSTM-CRF model with post inference to extract both Freebase-style events as well as multi-type event mentions on the
generated dataset. Our approach is shown to be effective in both manual and automatic evaluation tasks. 
